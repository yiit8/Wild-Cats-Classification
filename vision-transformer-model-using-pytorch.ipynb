{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import ConcatDataset\nimport time\nfrom tqdm import tqdm\nimport os\nfrom sklearn.model_selection import train_test_split\nimport copy\nimport glob\nimport timm\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:28.25952Z","iopub.execute_input":"2023-04-02T11:54:28.260147Z","iopub.status.idle":"2023-04-02T11:54:28.269077Z","shell.execute_reply.started":"2023-04-02T11:54:28.260108Z","shell.execute_reply":"2023-04-02T11:54:28.26801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cats-in-the-wild-image-classification/WILDCATS.CSV\")","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:28.274477Z","iopub.execute_input":"2023-04-02T11:54:28.2751Z","iopub.status.idle":"2023-04-02T11:54:28.28646Z","shell.execute_reply.started":"2023-04-02T11:54:28.275062Z","shell.execute_reply":"2023-04-02T11:54:28.284894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:28.288245Z","iopub.execute_input":"2023-04-02T11:54:28.28886Z","iopub.status.idle":"2023-04-02T11:54:28.301573Z","shell.execute_reply.started":"2023-04-02T11:54:28.288818Z","shell.execute_reply":"2023-04-02T11:54:28.300414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Visualization\n\nprint(df['labels'].value_counts())\nprint(df['labels'].value_counts().sum())\nplt.figure(figsize=(8,5))\nplt.xticks(rotation=90, fontsize=10)\nplt.yticks(fontsize=10)\nsns.countplot(x='labels', data=df, palette='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:28.303172Z","iopub.execute_input":"2023-04-02T11:54:28.303863Z","iopub.status.idle":"2023-04-02T11:54:28.554273Z","shell.execute_reply.started":"2023-04-02T11:54:28.303825Z","shell.execute_reply":"2023-04-02T11:54:28.553265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation and data definitions\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.Resize(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ColorJitter(),\n        transforms.GaussianBlur(kernel_size=(5,5)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test' : transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n}\n\ndata_dir = '/kaggle/input/cats-in-the-wild-image-classification'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n                  for x in ['train', 'valid','test']}\n\n# Split the 'train' dataset into train and validation sets\n\ntrain_data, val_data = train_test_split(image_datasets['train'], test_size=0.2, random_state=42)\nval_data, test_data = train_test_split(val_data, test_size=0.5, random_state=42)\n\n\n# Create the dataloaders for training, validation, and testing\ndataloaders = {'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4),\n               'valid': torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4),\n               'test' : torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)\n              }\n\ndataset_sizes = {'train': len(train_data), 'valid': len(val_data), 'test': len(test_data)}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:28.556253Z","iopub.execute_input":"2023-04-02T11:54:28.556948Z","iopub.status.idle":"2023-04-02T11:54:58.22673Z","shell.execute_reply.started":"2023-04-02T11:54:28.556891Z","shell.execute_reply":"2023-04-02T11:54:58.225662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:58.228151Z","iopub.execute_input":"2023-04-02T11:54:58.229177Z","iopub.status.idle":"2023-04-02T11:54:58.236234Z","shell.execute_reply.started":"2023-04-02T11:54:58.229126Z","shell.execute_reply":"2023-04-02T11:54:58.234967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Size of training data is:\")\nprint(len(train_data))\nprint('-' * 25)\nprint(\"Size of validation data is:\")\nprint(len(val_data))\nprint('-' * 25)\nprint(\"Size of test data is:\")\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:58.238347Z","iopub.execute_input":"2023-04-02T11:54:58.238759Z","iopub.status.idle":"2023-04-02T11:54:58.252563Z","shell.execute_reply.started":"2023-04-02T11:54:58.238718Z","shell.execute_reply":"2023-04-02T11:54:58.251555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Few images to visualize\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off') # remove axis ticks and labels\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\n# Get class labels\nlabel_names = [class_names[x] for x in classes]\n\n# Display images with labels in a row\nfig, axs = plt.subplots(1, 10, figsize=(15, 10))\n\nfor i in range(10):\n    axs[i].imshow(inputs[i].permute(1, 2, 0))\n    axs[i].set_title(label_names[i],fontsize=8)\n    axs[i].axis('off')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:58.254226Z","iopub.execute_input":"2023-04-02T11:54:58.254624Z","iopub.status.idle":"2023-04-02T11:54:59.096864Z","shell.execute_reply.started":"2023-04-02T11:54:58.254587Z","shell.execute_reply":"2023-04-02T11:54:59.095838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nfrom torch.utils.tensorboard import SummaryWriter\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=5, log_dir='./logs'):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n\n    # Create a TensorBoard summary writer\n    writer = SummaryWriter(log_dir)\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # Log the loss and accuracy to TensorBoard\n            writer.add_scalar(f'{phase}/loss', epoch_loss, epoch)\n            writer.add_scalar(f'{phase}/accuracy', epoch_acc, epoch)\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    # Close the TensorBoard writer\n    writer.close()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:59.098967Z","iopub.execute_input":"2023-04-02T11:54:59.099842Z","iopub.status.idle":"2023-04-02T11:54:59.114687Z","shell.execute_reply.started":"2023-04-02T11:54:59.099798Z","shell.execute_reply":"2023-04-02T11:54:59.11363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing predictions\n\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['valid']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:59.117786Z","iopub.execute_input":"2023-04-02T11:54:59.11832Z","iopub.status.idle":"2023-04-02T11:54:59.132396Z","shell.execute_reply.started":"2023-04-02T11:54:59.118276Z","shell.execute_reply":"2023-04-02T11:54:59.131377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained Vision Transformer model\nmodel_ft = timm.create_model('vit_base_patch16_224', pretrained=True)\n\n# Freeze all layers in the model\nfor param in model_ft.parameters():\n    param.requires_grad = False\n\n# Replace the classifier with a new one that is trainable\nnum_ftrs = model_ft.head.in_features\nmodel_ft.head = nn.Sequential(\n    nn.Linear(num_ftrs, 512),\n    nn.ReLU(inplace=True),\n    nn.Dropout(p=0.5),   # To prevent training data to overfit \n    nn.Linear(512, len(class_names))\n)\n\n# Move the model to the device (e.g. GPU)\nmodel_ft = model_ft.to(device)\n\n# Set up loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Set up optimizer (unfreeze the classifier's parameters)\noptimizer_ft = optim.Adam(model_ft.head.parameters(), lr=0.001)\n\n# Set up learning rate scheduler\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.25)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:54:59.134015Z","iopub.execute_input":"2023-04-02T11:54:59.13514Z","iopub.status.idle":"2023-04-02T11:55:16.286458Z","shell.execute_reply.started":"2023-04-02T11:54:59.135095Z","shell.execute_reply":"2023-04-02T11:55:16.285248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=12)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T11:55:16.288059Z","iopub.execute_input":"2023-04-02T11:55:16.288448Z","iopub.status.idle":"2023-04-02T12:01:16.623909Z","shell.execute_reply.started":"2023-04-02T11:55:16.288397Z","shell.execute_reply":"2023-04-02T12:01:16.621959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Few Predictions\nvisualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T12:06:52.628483Z","iopub.execute_input":"2023-04-02T12:06:52.629738Z","iopub.status.idle":"2023-04-02T12:06:54.114911Z","shell.execute_reply.started":"2023-04-02T12:06:52.629691Z","shell.execute_reply":"2023-04-02T12:06:54.113831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for images,labels in dataloaders['test']:\n        images, labels = images.cuda(), labels.cuda()\n        # calculate outputs by running images through the network\n        outputs = model_ft(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the test images: {100 * correct // total} %')","metadata":{"execution":{"iopub.status.busy":"2023-04-02T12:06:56.855286Z","iopub.execute_input":"2023-04-02T12:06:56.855922Z","iopub.status.idle":"2023-04-02T12:07:00.632022Z","shell.execute_reply.started":"2023-04-02T12:06:56.855852Z","shell.execute_reply":"2023-04-02T12:07:00.629431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['AFRICAN LEOPARD', 'CARACAL', 'CHEETAH', 'CLOUDED LEOPARD', 'JAGUAR', 'LIONS', 'OCELOT', 'PUMA', 'SNOW LEOPARD', 'TIGER']","metadata":{"execution":{"iopub.status.busy":"2023-04-02T12:08:57.800274Z","iopub.execute_input":"2023-04-02T12:08:57.801259Z","iopub.status.idle":"2023-04-02T12:08:57.807217Z","shell.execute_reply.started":"2023-04-02T12:08:57.801204Z","shell.execute_reply":"2023-04-02T12:08:57.805853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in class_names}\ntotal_pred = {classname: 0 for classname in class_names}\n\n# again no gradients needed\nwith torch.no_grad():\n    for images,labels in dataloaders['test']:\n        images, labels = images.cuda(), labels.cuda()\n        outputs = model_ft(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[class_names[label]] += 1\n            total_pred[class_names[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-02T12:10:16.430818Z","iopub.execute_input":"2023-04-02T12:10:16.432014Z","iopub.status.idle":"2023-04-02T12:10:20.047351Z","shell.execute_reply.started":"2023-04-02T12:10:16.43197Z","shell.execute_reply":"2023-04-02T12:10:20.046086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}